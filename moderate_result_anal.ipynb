{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "dir_path = '/home/elicer/honest_llama/moderate_result_hatexplain/'\n",
    "json_lists = os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/elicer/honest_llama/moderate_result_hatexplain/mydata_hatexplain_alpha_-10.0_numheads_12_0.json_moderate_concat.json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path+json_lists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "dir_path = '/home/elicer/honest_llama/moderate_result_hatexpliain_new/'\n",
    "json_lists = os.listdir(dir_path)\n",
    "\n",
    "score_list = []\n",
    "for i in range(len(json_lists)):\n",
    "    cur_path=dir_path+json_lists[i]\n",
    "    #print(cur_path)\n",
    "    with open(cur_path,'r') as f:\n",
    "        cur_json = json.load(f)\n",
    "    score = [0,0,0,0]\n",
    "    for j in cur_json:\n",
    "        score[0] += j['Hate severity']\n",
    "        score[1] += j['SelfHarm severity']\n",
    "        score[2] += j['Sexual severity']\n",
    "        score[3] += j['Violence severity']\n",
    "    cur_score=list(map(lambda x:round(x/len(cur_json),4), score))\n",
    "    splited = json_lists[i].split('_')\n",
    "    if len(splited)<=5:\n",
    "        #print(0,0,0)\n",
    "        score_list.append([0,0,0, cur_score])\n",
    "    else:\n",
    "        #print(int(float(splited[3])),int(splited[5]),int(splited[6][0]))\n",
    "        score_list.append([int(float(splited[3])),int(splited[5]),int(splited[6][0]), cur_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 36, 1, [0.3125, 0.0, 0.0469, 0.0781]], [15, 12, 0, [0.0625, 0.0156, 0.0, 0.0156]], [15, 12, 1, [0.4094, 0.0, 0.0157, 0.0787]], [15, 24, 0, [0.125, 0.0312, 0.0, 0.0]], [15, 24, 1, [0.0312, 0.0, 0.0, 0.0]], [15, 36, 0, [0.0156, 0.0156, 0.0, 0.0]], [15, 36, 1, [0.0, 0.0, 0.0, 0.0]], [15, 48, 0, [0.0156, 0.0156, 0.0, 0.0]], [15, 48, 1, [0.0, 0.0, 0.0, 0.0]], [10, 12, 0, [0.4219, 0.0, 0.0781, 0.0938]], [10, 12, 1, [0.6719, 0.0156, 0.0312, 0.1562]], [10, 24, 0, [0.2188, 0.0, 0.0, 0.0312]], [10, 24, 1, [0.3281, 0.0156, 0.0469, 0.0156]], [10, 36, 0, [0.4844, 0.0, 0.0312, 0.0312]], [10, 48, 0, [0.375, 0.0156, 0.0156, 0.0938]], [10, 48, 1, [0.2656, 0.0, 0.0781, 0.0312]], [5, 12, 0, [0.6562, 0.0156, 0.0625, 0.1406]], [5, 12, 1, [0.6094, 0.0, 0.0625, 0.1406]], [5, 24, 0, [0.7969, 0.0, 0.0781, 0.125]], [5, 24, 1, [0.5938, 0.0, 0.0469, 0.1875]], [5, 36, 0, [0.6719, 0.0312, 0.0938, 0.1562]], [5, 36, 1, [0.6094, 0.0, 0.0469, 0.0625]], [5, 48, 0, [0.9062, 0.0312, 0.1094, 0.1562]], [5, 48, 1, [0.625, 0.0, 0.0469, 0.0469]], [-15, 48, 1, [5.7969, 0.0, 0.0, 1.2188]], [-15, 12, 0, [4.9375, 0.0, 0.2188, 0.2031]], [-15, 12, 1, [5.0156, 0.0, 0.0469, 0.2344]], [-15, 24, 0, [5.6094, 0.0, 0.0, 0.1094]], [-15, 24, 1, [5.4531, 0.0, 0.0, 1.3281]], [-15, 36, 0, [5.7656, 0.0156, 0.0, 0.2188]], [-15, 36, 1, [5.4375, 0.0, 0.0, 1.7344]], [-15, 48, 0, [5.2969, 0.0, 0.0, 0.0469]], [-10, 12, 0, [4.0469, 0.0156, 0.0938, 0.375]]]\n"
     ]
    }
   ],
   "source": [
    "print(score_list)\n",
    "#list(map(lambda x: [x[0]/5,x[1]/12] score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited = json_lists[2].split('_')\n",
    "print(splited)\n",
    "print(int(float(splited[3])),int(splited[5]),int(splited[6][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start GPT3\n",
      "{\n",
      "  \"id\": \"cmpl-8RhFdiZDESDQh3lYVBFIydZTTOqIN\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1701611805,\n",
      "  \"model\": \"babbage-002.ft-9e0b989b9be2443a89aff2fde7b9d3bb\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \".\",\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"logprobs\": {\n",
      "        \"tokens\": [\n",
      "          \".\"\n",
      "        ],\n",
      "        \"token_logprobs\": [\n",
      "          -1.7161299\n",
      "        ],\n",
      "        \"top_logprobs\": [\n",
      "          {\n",
      "            \".\": -1.7161299,\n",
      "            \" A\": -2.3723798\n",
      "          }\n",
      "        ],\n",
      "        \"text_offset\": [\n",
      "          42\n",
      "        ]\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 16,\n",
      "    \"completion_tokens\": 1,\n",
      "    \"total_tokens\": 17\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"7859589320c944c3beac9917ebfd54d5\"\n",
    "openai.api_base =  \"https://23f-cs475-team9-ncus.openai.azure.com/\"\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-09-15-preview' # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    "print('start GPT3')\n",
    "\n",
    "try:\n",
    "    engine='GPT-info'\n",
    "    prompt = '''Q: What's you name? A: My name is Hyunseok'''\n",
    "\n",
    "    response = openai.Completion.create(engine=engine, prompt=prompt, temperature=0, max_tokens=1,\n",
    "                                        stop=None, echo=False, logprobs=2)\n",
    "    #sleep(0.1)  # avoid OpenAI's max calls limit\n",
    "    logprobs = response['choices'][0]['logprobs']\n",
    "    output_str = logprobs['tokens'][0]\n",
    "    output_dict = logprobs['top_logprobs'][0]\n",
    "    print(response)\n",
    "except Exception as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\": [\n",
      "    \".\"\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.7161299\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \".\": -1.7161299,\n",
      "      \" A\": -2.3723798\n",
      "    }\n",
      "  ],\n",
      "  \"text_offset\": [\n",
      "    42\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['logprobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1c12814e9e29166fdf8897794d9ae65caca46174b8a2d6751659285f12adf8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
